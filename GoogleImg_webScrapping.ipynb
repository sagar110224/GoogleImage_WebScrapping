{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,FunctionTransformer,OrdinalEncoder, LabelEncoder, OneHotEncoder, MinMaxScaler, PowerTransformer, KBinsDiscretizer, Binarizer, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.impute import KNNImputer,SimpleImputer,MissingIndicator\n",
    "from sklearn.compose import ColumnTransformer,make_column_transformer\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, r2_score, confusion_matrix, mean_absolute_error, mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import *\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import set_config\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDRegressor, Ridge, Lasso, ElasticNet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, GradientBoostingClassifier,AdaBoostClassifier, StackingClassifier\n",
    "\n",
    "from dtreeviz.trees import *\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import scipy.fft as fft,scipy.fftpack as fftpack\n",
    "import scipy.cluster.hierarchy as hc\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import mode\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits.mplot3d import proj3d\n",
    "from matplotlib.patches import FancyArrowPatch\n",
    "from optuna.visualization import plot_optimization_history, plot_parallel_coordinate, plot_slice, plot_contour, plot_param_importances\n",
    "\n",
    "import plotly.express as px\n",
    "from IPython.display import Image, display_svg,SVG\n",
    "\n",
    "import datetime\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "import optuna\n",
    "\n",
    "import random\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import requests\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "\n",
    "import threading\n",
    "import queue\n",
    "import shutil\n",
    "import undetected_chromedriver as uc\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Google_images_Web_scrapping:\n",
    "    \n",
    "    def __init__(self,chrome_driver_executablepath,folder_name,URL,Allimages_containerClass,previewImg_class,largeImg_xpath,proxy_file_loc):\n",
    "        self.URL=URL\n",
    "        self.folder_name=folder_name\n",
    "        self.previewImg_class=previewImg_class\n",
    "        self.largeImg_xpath=largeImg_xpath\n",
    "        self.proxy_file_loc=proxy_file_loc\n",
    "        self.Allimages_containerClass=Allimages_containerClass\n",
    "        self.chrome_driver_executablepath=chrome_driver_executablepath\n",
    "        \n",
    "        # self.container_xpath=container_xpath\n",
    "    def create_folder(self):\n",
    "        if not os.path.isdir(self.folder_name):\n",
    "            os.makedirs(self.folder_name) \n",
    "    \n",
    "    def search_URL(self):\n",
    "        global driver\n",
    "        cService=webdriver.ChromeService(executable_path=self.chrome_driver_executablepath)\n",
    "        driver=webdriver.Chrome(service=cService)\n",
    "        driver.get(self.URL)\n",
    "        time.sleep(1)\n",
    "        \n",
    "    def load_images(self,scroll_y):\n",
    "        global driver\n",
    "        driver.execute_script('window.scrollTo(0,%s);'%scroll_y)\n",
    "        time.sleep(6)\n",
    "        page_html=driver.page_source\n",
    "        pageSoup=BeautifulSoup(page_html,'html.parser')\n",
    "        containers=pageSoup.findAll(\"div\",{\"class\":self.Allimages_containerClass})\n",
    "        len_cont=len(containers)\n",
    "        print(len_cont)\n",
    "        return len_cont\n",
    "    \n",
    "    def download_img(self,url,num):\n",
    "        global proxies\n",
    "        response=requests.get(url,proxies={'http:':proxies,'https:':proxies})\n",
    "        if response.status_code==200:\n",
    "            with open(os.path.join(self.folder_name,str(num)+\".jpg\"),'wb') as file:\n",
    "                file.write(response.content)\n",
    "    \n",
    "    def load_and_downloadimages(self,len_container):\n",
    "        global count\n",
    "        global images_count\n",
    "        for i in range(count,len_container+1):\n",
    "            xpath=\"\"\"//*[@id=\"rso\"]/div/div/div[1]/div/div/div[%s]\"\"\"%i\n",
    "            previewImgPath=\"\"\"//*[@id=\"rso\"]/div/div/div[1]/div/div/div[%s]/a[1]/div[1]/g-img\"\"\"%i\n",
    "            \n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                previewImgElement=driver.find_element(By.XPATH,previewImgPath)\n",
    "            except:\n",
    "                preview_ImgElement=driver.find_element(By.CLASS_NAME,self.previewImg_class)\n",
    "                previewImgURL=preview_ImgElement.get_attribute('src')   \n",
    "                driver.find_element(By.XPATH,xpath).click()\n",
    "                time.sleep(3)\n",
    "                timeStarted=time.time()\n",
    "                cond=True\n",
    "                while cond==True:\n",
    "                    largeView_ImgElement=driver.find_element(By.XPATH,self.largeImg_xpath)\n",
    "                    largeView_ImgURL=largeView_ImgElement.get_attribute('src') \n",
    "                    print(largeView_ImgURL)\n",
    "                    if largeView_ImgURL!=previewImgURL:\n",
    "                        cond=False\n",
    "                    else:\n",
    "                        currentTime=time.time()\n",
    "                        if currentTime-timeStarted>10:\n",
    "                            print(\"Time to load large image is greater than 10 seconds\")\n",
    "                            cond=False\n",
    "                \n",
    "                try:\n",
    "                    self.download_img(largeView_ImgURL,i)\n",
    "                    images_count+=1\n",
    "                    print(\"Downloaded element %s out of %s total. URL: %s\"%(i,len_container+1,largeView_ImgURL))\n",
    "                    print(f'images_count={images_count}, count={count}')\n",
    "                except:\n",
    "                    print(\"Couldn't download image %s\"%i)\n",
    "        \n",
    "    \n",
    "    def get_images(self,number_of_images):\n",
    "        global driver\n",
    "        global images_count\n",
    "        global count\n",
    "        global proxies\n",
    "        with open(self.proxy_file_loc,'r') as f:\n",
    "            proxies=f.read().split('\\n')\n",
    "        images_count=0\n",
    "        count=1\n",
    "        scroll_y=1\n",
    "        self.create_folder()\n",
    "        self.search_URL()\n",
    "        print('scroll_y=',scroll_y)\n",
    "        len_container=self.load_images(str(scroll_y))\n",
    "        self.load_and_downloadimages(len_container)\n",
    "        count=len_container\n",
    "        \n",
    "        \n",
    "        while images_count<number_of_images:\n",
    "            scroll_y=scroll_y*10000\n",
    "            print('scroll_y=',scroll_y)\n",
    "            len_container=self.load_images(scroll_y)\n",
    "            self.load_and_downloadimages(len_container)\n",
    "            count=len_container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleImgWebScrapping=Google_images_Web_scrapping(chrome_driver_executablepath='/Users/drago/Documents/chromedriver-mac-arm64/chromedriver',\n",
    "                                                  folder_name='Messi images',\n",
    "                                                  URL='https://www.google.com/search?q=messi&sca_esv=d609cd469e173d32&udm=2&biw=1280&bih=659&sxsrf=ADLYWILVFjfj47il1b7q3vzf4kH0bQ5fPg%3A1736381548241&ei=bBR_Z8mzDq-q4-EP2ujQmA8&ved=0ahUKEwjJmYKrreeKAxUv1TgGHVo0FPMQ4dUDCBA&uact=5&oq=messi&gs_lp=EgNpbWciBW1lc3NpMgQQIxgnMgQQIxgnMgoQABiABBhDGIoFMgoQABiABBhDGIoFMgoQABiABBhDGIoFMgoQABiABBhDGIoFMgoQABiABBhDGIoFMgoQABiABBhDGIoFMgoQABiABBhDGIoFMg0QABiABBixAxhDGIoFSLIJUABYtwVwAHgAkAEAmAF8oAHXBKoBAzAuNbgBA8gBAPgBAZgCBaAC7gTCAggQABiABBixA8ICCxAAGIAEGLEDGIMBwgIFEAAYgATCAg4QABiABBixAxiDARiKBcICChAAGIAEGLEDGAqYAwCSBwMwLjWgB9ck&sclient=img',\n",
    "                                                  Allimages_containerClass=\"eA0Zlc WghbWd FnEtTd mkpRId m3LIae RLdvSe qyKxnc ivg-i PZPZlf GMCzAd\",\n",
    "                                                  previewImg_class=\"YQ4gaf\",\n",
    "                                                  largeImg_xpath='//*[@id=\"Sva75c\"]/div[2]/div[2]/div/div[2]/c-wiz/div/div[3]/div[1]/a/img[1]',\n",
    "                                                  proxy_file_loc='/Users/drago/Documents/Practice files/Data_files/valid_proxies.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GoogleImgWebScrapping.get_images(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial=trial()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
